{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "import pydicom as dicom\n",
    "import os\n",
    "# import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "# from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "import scipy\n",
    "\n",
    "# from skimage import morphology\n",
    "# from skimage import measure\n",
    "# from skimage import feature\n",
    "# from skimage.transform import resize\n",
    "# from skimage.filters import threshold_otsu, threshold_local, median, gaussian, wiener,sobel, hessian, prewitt\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# from plotly import __version__\n",
    "# from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "# import plotly.figure_factory as FF\n",
    "# from plotly.graph_objs import *\n",
    "\n",
    "from mayavi import mlab\n",
    "from tvtk.api import tvtk\n",
    "from trimesh import Trimesh\n",
    "# from scipy import stats\n",
    "# import skimage\n",
    "\n",
    "# init_notebook_mode(connected=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetSTL(CTDir = 'D:\\Shirshak\\Research\\BabelBrain\\Tests\\CT_Test', \n",
    "           CTFile = 'CT_Phantom.nii.gz',\n",
    "           STLFile ='bone.stl'):\n",
    "    # sitk image reader\n",
    "    imgMain = sitk.ReadImage(CTDir+os.sep+CTFile)\n",
    "    imgOriginal = imgMain\n",
    "    # threshold the image with upper and lower threshold values\n",
    "    imgThreshold = sitk.DoubleThreshold(\n",
    "            imgOriginal, 350, 350, 350, 5000, 1, 0)\n",
    "    # convert the images into numpy array from sitk images\n",
    "    imgArray = sitk.GetArrayFromImage(imgThreshold)\n",
    "    imgMainArray = sitk.GetArrayFromImage(imgMain)\n",
    "    imgOriginalArray = sitk.GetArrayFromImage(imgOriginal)\n",
    "    # Get spacing origin and the direction of the images\n",
    "    spacing = np.asarray(imgOriginal.GetSpacing())\n",
    "    origin = np.asarray(imgOriginal.GetOrigin())\n",
    "    direction = np.asarray(imgOriginal.GetDirection())\n",
    "    # print(spacing)\n",
    "\n",
    "    # Swap the axes of the image stack to match with the spacing, origin and direction axes\n",
    "    imgArray = np.swapaxes(imgArray, 0, 2)\n",
    "    edges = imgArray\n",
    "    # Perform morpology in the image\n",
    "    edges=scipy.ndimage.binary_erosion(imgArray,iterations=2)*1.0\n",
    "    edges=scipy.ndimage.binary_dilation(imgArray,iterations=2)*1.0\n",
    "    imgTo3D = edges\n",
    "    SkullRing, points, faces,normals,result,compute_normals = ObtainSkullSurfaceAndRing(imgTo3D,spacing, origin)\n",
    "    boneMesh = Trimesh(vertices=points,faces=faces)\n",
    "    boneMesh.export(CTDir+os.sep+STLFile)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to construct the surface of the skull using contours\n",
    "def ObtainSkullSurfaceAndRing(MaterialMap, spacing, origin):\n",
    "    SkullRegion=MaterialMap!=0\n",
    "    SkullRing=np.logical_xor(scipy.ndimage.binary_dilation(SkullRegion),scipy.ndimage.binary_erosion(SkullRegion))\n",
    "    \n",
    "    # print (\"0\");\n",
    "    \n",
    "    data=SkullRegion.copy()\n",
    "#     perfform dilation\n",
    "    data=scipy.ndimage.binary_dilation(data,iterations=1)*1.0\n",
    "    \n",
    "    # print (\"1\");\n",
    "    \n",
    "\n",
    "#     Convert the image into a scalar field\n",
    "    src = mlab.pipeline.scalar_field(data)\n",
    "#     Set the origin and the spacing\n",
    "    src.spacing = spacing\n",
    "    src.update_image_data = True\n",
    "    src.origin=origin\n",
    "\n",
    "    \n",
    "    # print (\"2\");\n",
    "    \n",
    "    srcOrig = mlab.pipeline.scalar_field((SkullRing)*1.0)\n",
    "    srcOrig.spacing = spacing\n",
    "    srcOrig.update_image_data = True\n",
    "    srcOrig.origin=origin\n",
    "\n",
    "    # print (\"3\");\n",
    "\n",
    "#   Add median filter to the pipeline to remove any noise\n",
    "    median_filter = tvtk.ImageMedian3D()\n",
    "    try:\n",
    "        median_filter.set_kernel_size(3, 3, 3)\n",
    "    except AttributeError:\n",
    "        median_filter.kernel_size = [3, 3, 3]\n",
    "    \n",
    "    # print (\"4\");\n",
    "    \n",
    "    median = mlab.pipeline.user_defined(src, filter=median_filter)\n",
    "\n",
    "#     Difussion filter to remove the noise\n",
    "    diffuse_filter = tvtk.ImageAnisotropicDiffusion3D(\n",
    "                                        diffusion_factor=0.5,\n",
    "                                        diffusion_threshold=1,\n",
    "                                        number_of_iterations=1)\n",
    "\n",
    "    # print (\"5\");\n",
    "    \n",
    "    diffuse = mlab.pipeline.user_defined(median, filter=diffuse_filter)\n",
    "\n",
    "    # print (\"6\");\n",
    "# create contour of the image\n",
    "    contour = mlab.pipeline.contour(diffuse, )\n",
    "\n",
    "    # print (\"7\");\n",
    "    \n",
    "    contour.filter.contours = [1, ]\n",
    "# Aply decimation\n",
    "    dec = mlab.pipeline.decimate_pro(contour)\n",
    "    dec.filter.feature_angle = 90.\n",
    "    dec.filter.target_reduction = 0.6\n",
    "\n",
    "#     Apply smoothing filter\n",
    "    smooth_ = tvtk.SmoothPolyDataFilter(\n",
    "                        number_of_iterations=100,\n",
    "                        relaxation_factor=0.1,\n",
    "                        feature_angle=90,\n",
    "                        feature_edge_smoothing=False,\n",
    "                        boundary_smoothing=False,\n",
    "                        convergence=0.,\n",
    "                    )\n",
    "    smooth = mlab.pipeline.user_defined(dec, filter=smooth_)\n",
    "    \n",
    "    # print (\"8\");\n",
    "    \n",
    "    # Get the largest connected region\n",
    "    connect_ = tvtk.PolyDataConnectivityFilter(extraction_mode=4)\n",
    "    connect = mlab.pipeline.user_defined(smooth, filter=connect_)\n",
    "    \n",
    "    # print (\"9\");\n",
    "    \n",
    "    # Compute normals for shading the surface\n",
    "    compute_normals = mlab.pipeline.poly_data_normals(connect)\n",
    "    compute_normals.filter.feature_angle = 80.\n",
    "\n",
    "# get vertices and faces\n",
    "    result=compute_normals.get_output_dataset()\n",
    "    normals= np.array(result.point_data.normals)\n",
    "    faces=result.polys.get_data().to_array().reshape((result.polys.number_of_cells,4))[:,1:4]\n",
    "\n",
    "    points=np.array(result.points)\n",
    "    points[:,0]-=1\n",
    "    points[:,1]-=1\n",
    "    points[:,2]-=1\n",
    "    return SkullRing, points, faces,normals,result,compute_normals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "GetSTL()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BabelBrain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
